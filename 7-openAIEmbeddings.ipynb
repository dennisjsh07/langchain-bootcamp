{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ea0020",
   "metadata": {},
   "source": [
    "#### Open AI Embeddings\n",
    "- https://docs.langchain.com/oss/python/integrations/text_embedding/openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e58a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3292be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the OpenAI API key from environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8675592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "text2 = (\n",
    "    \"LangChain is a framework for developing applications powered by language models\"\n",
    ")\n",
    "\n",
    "single_vector = embeddings.embed_query(text)\n",
    "print(len(single_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f918332",
   "metadata": {},
   "source": [
    "#### Converting to 1024 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe0a2025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "embeddings_1024 = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=1024)\n",
    "\n",
    "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "\n",
    "single_vector = embeddings_1024.embed_query(text)\n",
    "print(len(single_vector))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1675c47e",
   "metadata": {},
   "source": [
    "#### RAG Example with Chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e6d6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results for the query: 'What is the main message of the speech?'\n",
      "Result 1: The present asks us to build with integrity and compassion.\n",
      "The future depends on how wisely we use our freedom today.\n",
      "Independence lives on when we choose progress over fear.\n",
      "\n",
      "Result 2: Freedom was not gifted; it was earned through courage and sacrifice.\n",
      "Countless voices rose together to demand dignity and self-rule.\n",
      "Every step toward independence carried the weight of hope and loss.\n",
      "The struggle taught us unity beyond language, region, or belief.\n",
      "Independence is not just a date, but a responsibility we carry daily.\n",
      "It reminds us to protect justice, equality, and truth.\n",
      "The past whispers lessons of resilience and bravery.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the embeddings in croma database and perform similarity search\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(\n",
    "    docs\n",
    ")  # here incoming format is already a document\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=texts, embedding=embeddings_1024, collection_name=\"speech_collection\")\n",
    "query = \"What is the main message of the speech?\"\n",
    "results = vectorstore.similarity_search(query=query, k=3)\n",
    "\n",
    "print(f\"Top 3 results for the query: '{query}'\")\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"Result {i+1}: {res.page_content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
