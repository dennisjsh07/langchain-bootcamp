{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca149c0",
   "metadata": {},
   "source": [
    "### Chat bot with conversation history\n",
    "https://reference.langchain.com/python/langchain-core/messages/human/HumanMessage\n",
    "https://docs.langchain.com/oss/python/langchain/messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba412304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b09e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(\n",
    "    model=\"qwen/qwen3-32b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09deef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Dennis! It's a pleasure to meet you. As a Chief AI Engineer, you're likely at the forefront of some fascinating projects. I'd love to hear more about your current workâ€”whether it's in machine learning, natural language processing, computer vision, or any emerging AI technologies. \\n\\nAre you working on any specific challenges or innovations that you'd like to discuss? Whether it's technical hurdles, ethical considerations, or strategic implementations, I'm here to engage in a meaningful dialogue. Collaboration and knowledge-sharing are key in our field, so feel free to dive into any topic that interests you!\", additional_kwargs={'reasoning_content': \"Okay, the user introduced himself as Dennis, a chief AI engineer. First, I need to acknowledge his introduction and express interest in his work. Since he's in a technical field, maybe he's looking for technical discussions or advice. I should ask about his current projects or challenges he's facing. Also, considering his role, he might be interested in collaboration opportunities or sharing knowledge. I should keep the conversation open-ended to let him decide the direction. Need to make sure the response is friendly and professional, matching his level of expertise. Maybe mention specific areas like machine learning, deep learning, or AI ethics if he's interested. Avoid being too generic. Let him know I'm here to help with any specific questions he might have.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 21, 'total_tokens': 295, 'completion_time': 0.564555356, 'completion_tokens_details': {'reasoning_tokens': 148}, 'prompt_time': 0.0007223, 'prompt_tokens_details': None, 'queue_time': 0.04696852, 'total_time': 0.565277656}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95a1-a61e-70d3-855e-2d7309db73a3-0', usage_metadata={'input_tokens': 21, 'output_tokens': 274, 'total_tokens': 295, 'output_token_details': {'reasoning': 148}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi my name is dennis, i'm a chief AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c8675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is **Dennis**, and you are a **Chief AI Engineer**. Youâ€™re likely involved in designing, developing, and overseeing AI systems, whether thatâ€™s building machine learning models, leading teams, or innovating in areas like NLP, computer vision, or AI ethics. \\n\\nIf youâ€™d like to dive deeper into any specific projects, challenges, or ideas related to your work, feel free to shareâ€”Iâ€™m here to help brainstorm, troubleshoot, or explore concepts with you! ðŸ˜Š', additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What is my name and what do I do?\" Let me check the conversation history.\\n\\nIn the previous message, the user introduced themselves as Dennis, a Chief AI Engineer. The assistant acknowledged that and asked about their work. Now, Dennis is asking again for confirmation of their name and role. \\n\\nHmm, maybe Dennis wants to ensure that the assistant correctly remembers their information. It\\'s possible they\\'re testing if the AI can retain context from the conversation. Alternatively, they might be verifying that the assistant is paying attention. \\n\\nI should confirm their name and role clearly. Since the assistant already knows from the history, the response should be straightforward. But maybe add a friendly touch to acknowledge the confirmation. Also, offer to help with any specific tasks related to their role as a Chief AI Engineer. \\n\\nWait, the user might be setting up for a deeper conversation. By confirming their identity, they might want to discuss projects, challenges, or ideas. The assistant should be ready to pivot into those topics. \\n\\nI need to make sure the response is accurate and helpful. No need to overcomplicate. Just state the name and role, then invite them to share more if they want. Keep it concise and positive.\\n'}, response_metadata={'token_usage': {'completion_tokens': 358, 'prompt_tokens': 162, 'total_tokens': 520, 'completion_time': 0.817698845, 'completion_tokens_details': {'reasoning_tokens': 251}, 'prompt_time': 0.006627001, 'prompt_tokens_details': None, 'queue_time': 0.045824779, 'total_time': 0.824325846}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95a4-8938-72e3-99f2-4aa9713f3568-0', usage_metadata={'input_tokens': 162, 'output_tokens': 358, 'total_tokens': 520, 'output_token_details': {'reasoning': 251}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi my name is dennis, i'm a chief AI engineer\"),\n",
    "        AIMessage(content=\"Hello Dennis! It's a pleasure to meet you. As a Chief AI Engineer, you're likely at the forefront of some fascinating projects. I'd love to hear more about your current workâ€”whether it's in machine learning, natural language processing, computer vision, or any emerging AI technologies. \\n\\nAre you working on any specific challenges or innovations that you'd like to discuss? Whether it's technical hurdles, ethical considerations, or strategic implementations, I'm here to engage in a meaningful dialogue. Collaboration and knowledge-sharing are key in our field, so feel free to dive into any topic that interests you!\", additional_kwargs={'reasoning_content': \"Okay, the user introduced himself as Dennis, a chief AI engineer. First, I need to acknowledge his introduction and express interest in his work. Since he's in a technical field, maybe he's looking for technical discussions or advice. I should ask about his current projects or challenges he's facing. Also, considering his role, he might be interested in collaboration opportunities or sharing knowledge. I should keep the conversation open-ended to let him decide the direction. Need to make sure the response is friendly and professional, matching his level of expertise. Maybe mention specific areas like machine learning, deep learning, or AI ethics if he's interested. Avoid being too generic. Let him know I'm here to help with any specific questions he might have.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 21, 'total_tokens': 295, 'completion_time': 0.564555356, 'completion_tokens_details': {'reasoning_tokens': 148}, 'prompt_time': 0.0007223, 'prompt_tokens_details': None, 'queue_time': 0.04696852, 'total_time': 0.565277656}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95a1-a61e-70d3-855e-2d7309db73a3-0', usage_metadata={'input_tokens': 21, 'output_tokens': 274, 'total_tokens': 295, 'output_token_details': {'reasoning': 148}}),\n",
    "        HumanMessage(content=\"What is my name and what do i do?\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed566d",
   "metadata": {},
   "source": [
    "### session management & message history\n",
    "https://medium.com/@jkSurampudi5/message-history-in-langchain-8b6c10e89e60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6d34c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing function to retrive chat history for a specific session_id\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "# function to retrive chat history for a specific session_id\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b47d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the session configuration\n",
    "config1 = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d263a3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Dennis! Nice to meet you. As an AI developer, you likely work on machine learning models, neural networks, or AI-driven solutions. How can I assist you today? Whether it's about model training, deployment, data preprocessing, AI ethics, tools like TensorFlow/PyTorch, or anything else in the AI/ML spaceâ€”feel free to share what you're working on! ðŸ˜Š\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the function\n",
    "response1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is dennis. I am a AI developer\")],\n",
    "    config=config1,\n",
    ")\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d14d252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Dennis! Your name is **Dennis**, as you mentioned earlier. ðŸ˜Š Let me know how I can assist you with your AI development work!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1,\n",
    ")\n",
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f7f4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi my name is Krishna. I am a Data Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Krishna! Nice to meet you. As a Data Engineer, you probably work with data pipelines, ETL processes, and infrastructure. How can I assist you today? Whether it's about data engineering challenges, tools, best practices, or anything else related to your work, feel free to ask!\", additional_kwargs={'reasoning_content': \"Okay, the user introduced themselves as Krishna, a Data Engineer. I should acknowledge their introduction and offer assistance. Let me make sure to respond warmly and ask how I can help them today. I'll keep it friendly and open-ended.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 19, 'total_tokens': 131, 'completion_time': 0.244956983, 'completion_tokens_details': {'reasoning_tokens': 47}, 'prompt_time': 0.000655941, 'prompt_tokens_details': None, 'queue_time': 0.046034125, 'total_time': 0.245612924}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c6-c2c0-7401-bbb8-a096b893af91-0', usage_metadata={'input_tokens': 19, 'output_tokens': 112, 'total_tokens': 131, 'output_token_details': {'reasoning': 47}}), HumanMessage(content='Hi my name is Krishna. I am a Data Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Krishna! Nice to meet you again. As a Data Engineer, you likely work with data pipelines, ETL processes, and infrastructure. How can I assist you today? Whether it's about data engineering challenges, tools, best practices, or anything else related to your work, feel free to ask!\", additional_kwargs={'reasoning_content': \"Okay, the user introduced themselves again as Krishna, a Data Engineer. Let me check the history. The previous message was the same, so maybe they sent it twice by accident. I should acknowledge their introduction again but also prompt them to ask a question or share what they need help with. Since they're a Data Engineer, they might need assistance with tools like Apache Airflow, Spark, or cloud services like AWS/GCP. I should keep the response friendly and open-ended to encourage them to specify their needs. Let me make sure the response is welcoming and offers help in areas relevant to their role.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 187, 'prompt_tokens': 100, 'total_tokens': 287, 'completion_time': 0.366594677, 'completion_tokens_details': {'reasoning_tokens': 121}, 'prompt_time': 0.003835218, 'prompt_tokens_details': None, 'queue_time': 0.046723868, 'total_time': 0.370429895}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c6-dde8-7683-ad90-cf2ebf234f71-0', usage_metadata={'input_tokens': 100, 'output_tokens': 187, 'total_tokens': 287, 'output_token_details': {'reasoning': 121}}), HumanMessage(content='My name is dennis. I am a AI developer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Dennis! Nice to meet you. As an AI developer, you likely work on machine learning models, neural networks, or AI-driven solutions. How can I assist you today? Whether it's about model training, deployment, data preprocessing, AI ethics, tools like TensorFlow/PyTorch, or anything else in the AI/ML spaceâ€”feel free to share what you're working on! ðŸ˜Š\", additional_kwargs={'reasoning_content': \"Okay, the user introduced themselves as Dennis, an AI developer. Let me check the history. The previous user was Krishna, a Data Engineer. Now Dennis is new.\\n\\nFirst, I need to acknowledge Dennis's introduction. Since he's an AI developer, maybe he works with machine learning models, frameworks like TensorFlow or PyTorch, or deals with training and deployment. \\n\\nI should ask how I can assist him. Possible areas could be model optimization, data preprocessing, deployment strategies, or AI ethics. Also, maybe he's interested in tools or best practices. \\n\\nI should keep the response friendly and open-ended to encourage him to specify his needs. Make sure not to assume too much but offer a range of possibilities. Let me phrase it in a way that invites him to share more about his current projects or challenges.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 251, 'prompt_tokens': 182, 'total_tokens': 433, 'completion_time': 0.484396823, 'completion_tokens_details': {'reasoning_tokens': 165}, 'prompt_time': 0.007439708, 'prompt_tokens_details': None, 'queue_time': 0.045811672, 'total_time': 0.491836531}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c7-2af0-71f1-957a-1acd218f77e4-0', usage_metadata={'input_tokens': 182, 'output_tokens': 251, 'total_tokens': 433, 'output_token_details': {'reasoning': 165}}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi Dennis! Your name is **Dennis**, as you mentioned earlier. ðŸ˜Š Let me know how I can assist you with your AI development work!', additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What is my name?\" Let me check the conversation history.\\n\\nLooking back, the user first introduced themselves as Krishna, a Data Engineer. Then they said, \"Hi my name is dennis. I am a AI developer.\" So there\\'s a switch here. The user might be testing if I remember the name change or if I can track the context correctly.\\n\\nWait, but in the previous messages, the user first said Krishna, then Dennis. The last message before the current one was from Dennis. So the current user is Dennis. But the user is asking \"What is my name?\" which could be a test to see if I can recall the correct name based on the conversation flow.\\n\\nI need to make sure I address the correct person. Since the last message was from Dennis, the current user is Dennis. However, the user might be trying to confirm if I can track the context properly. Alternatively, maybe there\\'s a confusion in the conversation history.\\n\\nWait, the user might be using multiple identities in the same conversation. But in the history, after Krishna, the user introduced Dennis. So the latest user is Dennis. The question is, when Dennis asks \"What is my name?\", I should respond with Dennis. But maybe the user is checking if I can handle multiple users in the same thread. However, in the current setup, each conversation is with one user. So perhaps the user is testing if I can remember the correct name after switching from Krishna to Dennis.\\n\\nIn that case, the correct answer is Dennis. But I need to make sure I don\\'t mix up the names. Let me verify again. The user first said Krishna, then Dennis. The last message was from Dennis. So the current user is Dennis. Therefore, the answer should be Dennis. But maybe the user is trying to see if I can track the context correctly. So I should respond with Dennis and acknowledge the previous names if necessary. However, the user might just want the current name. Let me check the instructions again. The user wants the assistant to provide a helpful and accurate response. So the correct answer is Dennis. I should respond with that.\\n'}, response_metadata={'token_usage': {'completion_tokens': 474, 'prompt_tokens': 278, 'total_tokens': 752, 'completion_time': 1.5791369259999999, 'completion_tokens_details': {'reasoning_tokens': 438}, 'prompt_time': 0.01220874, 'prompt_tokens_details': None, 'queue_time': 0.158936788, 'total_time': 1.591345666}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c7-8393-7e61-a253-0f372957ed43-0', usage_metadata={'input_tokens': 278, 'output_tokens': 474, 'total_tokens': 752, 'output_token_details': {'reasoning': 438}})]\n"
     ]
    }
   ],
   "source": [
    "print(store[\"chat1\"].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16b212e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have access to your personal information, including your name. If you'd like me to address you by name in our conversation, feel free to share it with me!\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the session config and ask for your name again\n",
    "config2 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "\n",
    "response1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config2,\n",
    ")\n",
    "response1.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
