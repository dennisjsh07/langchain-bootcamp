{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca149c0",
   "metadata": {},
   "source": [
    "### Chat bot with conversation history\n",
    "\n",
    "https://reference.langchain.com/python/langchain-core/messages/human/HumanMessage\n",
    "https://docs.langchain.com/oss/python/langchain/messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba412304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b09e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(\n",
    "    model=\"qwen/qwen3-32b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09deef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Dennis! It's a pleasure to meet you. As a chief AI engineer, you're likely at the forefront of some fascinating work. I'd love to hear more about your current projects or any challenges you're tackling in the field. Whether it's about machine learning models, AI ethics, or the latest advancements in neural networks, I'm here to engage in meaningful discussions and explore ideas together. What's on your mind today?\", additional_kwargs={'reasoning_content': \"Okay, the user introduced himself as Dennis, a chief AI engineer. First, I need to respond warmly and show respect for his professional background. I should ask about his specific work content or challenges he's facing to better understand his needs. At the same time, I need to keep the conversation open-ended to encourage him to share more information. I should also consider his possible needs, such as technical support, project collaboration, or career development advice. I need to maintain a friendly and professional tone, avoiding overly technical jargon to ensure the conversation is accessible. Additionally, I should be ready to offer assistance based on his responses, whether it's discussing AI trends, problem-solving, or other related topics. I need to make sure my response is concise and clear, allowing him to guide the conversation in the direction he's most interested in.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 260, 'prompt_tokens': 21, 'total_tokens': 281, 'completion_time': 0.629114083, 'completion_tokens_details': {'reasoning_tokens': 168}, 'prompt_time': 0.001696133, 'prompt_tokens_details': None, 'queue_time': 0.159804802, 'total_time': 0.630810216}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c9ad6-1a47-7f02-8d7f-c41cf71ba480-0', usage_metadata={'input_tokens': 21, 'output_tokens': 260, 'total_tokens': 281, 'output_token_details': {'reasoning': 168}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi my name is dennis, i'm a chief AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is **Dennis**, and you are a **Chief AI Engineer**. You‚Äôre likely involved in designing, developing, and overseeing AI systems, whether that‚Äôs building machine learning models, leading teams, or innovating in areas like NLP, computer vision, or AI ethics. \\n\\nIf you‚Äôd like to dive deeper into any specific projects, challenges, or ideas related to your work, feel free to share‚ÄîI‚Äôm here to help brainstorm, troubleshoot, or explore concepts with you! üòä', additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What is my name and what do I do?\" Let me check the conversation history.\\n\\nIn the previous message, the user introduced themselves as Dennis, a Chief AI Engineer. The assistant acknowledged that and asked about their work. Now, Dennis is asking again for confirmation of their name and role. \\n\\nHmm, maybe Dennis wants to ensure that the assistant correctly remembers their information. It\\'s possible they\\'re testing if the AI can retain context from the conversation. Alternatively, they might be verifying that the assistant is paying attention. \\n\\nI should confirm their name and role clearly. Since the assistant already knows from the history, the response should be straightforward. But maybe add a friendly touch to acknowledge the confirmation. Also, offer to help with any specific tasks related to their role as a Chief AI Engineer. \\n\\nWait, the user might be setting up for a deeper conversation. By confirming their identity, they might want to discuss projects, challenges, or ideas. The assistant should be ready to pivot into those topics. \\n\\nI need to make sure the response is accurate and helpful. No need to overcomplicate. Just state the name and role, then invite them to share more if they want. Keep it concise and positive.\\n'}, response_metadata={'token_usage': {'completion_tokens': 358, 'prompt_tokens': 162, 'total_tokens': 520, 'completion_time': 0.817698845, 'completion_tokens_details': {'reasoning_tokens': 251}, 'prompt_time': 0.006627001, 'prompt_tokens_details': None, 'queue_time': 0.045824779, 'total_time': 0.824325846}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95a4-8938-72e3-99f2-4aa9713f3568-0', usage_metadata={'input_tokens': 162, 'output_tokens': 358, 'total_tokens': 520, 'output_token_details': {'reasoning': 251}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi my name is dennis, i'm a chief AI engineer\"),\n",
    "        AIMessage(\n",
    "            content=\"Hello Dennis! It's a pleasure to meet you. As a Chief AI Engineer, you're likely at the forefront of some fascinating projects. I'd love to hear more about your current work‚Äîwhether it's in machine learning, natural language processing, computer vision, or any emerging AI technologies. \\n\\nAre you working on any specific challenges or innovations that you'd like to discuss? Whether it's technical hurdles, ethical considerations, or strategic implementations, I'm here to engage in a meaningful dialogue. Collaboration and knowledge-sharing are key in our field, so feel free to dive into any topic that interests you!\",\n",
    "            additional_kwargs={\n",
    "                \"reasoning_content\": \"Okay, the user introduced himself as Dennis, a chief AI engineer. First, I need to acknowledge his introduction and express interest in his work. Since he's in a technical field, maybe he's looking for technical discussions or advice. I should ask about his current projects or challenges he's facing. Also, considering his role, he might be interested in collaboration opportunities or sharing knowledge. I should keep the conversation open-ended to let him decide the direction. Need to make sure the response is friendly and professional, matching his level of expertise. Maybe mention specific areas like machine learning, deep learning, or AI ethics if he's interested. Avoid being too generic. Let him know I'm here to help with any specific questions he might have.\\n\"\n",
    "            },\n",
    "            response_metadata={\n",
    "                \"token_usage\": {\n",
    "                    \"completion_tokens\": 274,\n",
    "                    \"prompt_tokens\": 21,\n",
    "                    \"total_tokens\": 295,\n",
    "                    \"completion_time\": 0.564555356,\n",
    "                    \"completion_tokens_details\": {\"reasoning_tokens\": 148},\n",
    "                    \"prompt_time\": 0.0007223,\n",
    "                    \"prompt_tokens_details\": None,\n",
    "                    \"queue_time\": 0.04696852,\n",
    "                    \"total_time\": 0.565277656,\n",
    "                },\n",
    "                \"model_name\": \"qwen/qwen3-32b\",\n",
    "                \"system_fingerprint\": \"fp_5cf921caa2\",\n",
    "                \"service_tier\": \"on_demand\",\n",
    "                \"finish_reason\": \"stop\",\n",
    "                \"logprobs\": None,\n",
    "                \"model_provider\": \"groq\",\n",
    "            },\n",
    "            id=\"lc_run--019c95a1-a61e-70d3-855e-2d7309db73a3-0\",\n",
    "            usage_metadata={\n",
    "                \"input_tokens\": 21,\n",
    "                \"output_tokens\": 274,\n",
    "                \"total_tokens\": 295,\n",
    "                \"output_token_details\": {\"reasoning\": 148},\n",
    "            },\n",
    "        ),\n",
    "        HumanMessage(content=\"What is my name and what do i do?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed566d",
   "metadata": {},
   "source": [
    "### session management & message history\n",
    "\n",
    "https://medium.com/@jkSurampudi5/message-history-in-langchain-8b6c10e89e60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d34c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing function to retrive chat history for a specific session_id\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "# function to retrive chat history for a specific session_id\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b47d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the session configuration\n",
    "config1 = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263a3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Dennis! Nice to meet you. As an AI developer, you likely work on machine learning models, neural networks, or AI-driven solutions. How can I assist you today? Whether it's about model training, deployment, data preprocessing, AI ethics, tools like TensorFlow/PyTorch, or anything else in the AI/ML space‚Äîfeel free to share what you're working on! üòä\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the function\n",
    "response1 = with_message_history.invoke(  # the meaning of this line is to call the model with message history\n",
    "    [HumanMessage(content=\"My name is dennis. I am a AI developer\")],\n",
    "    config=config1,\n",
    ")\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d14d252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Dennis! Your name is **Dennis**, as you mentioned earlier. üòä Let me know how I can assist you with your AI development work!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config1,\n",
    ")\n",
    "response2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f7f4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi my name is Krishna. I am a Data Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Krishna! Nice to meet you. As a Data Engineer, you probably work with data pipelines, ETL processes, and infrastructure. How can I assist you today? Whether it's about data engineering challenges, tools, best practices, or anything else related to your work, feel free to ask!\", additional_kwargs={'reasoning_content': \"Okay, the user introduced themselves as Krishna, a Data Engineer. I should acknowledge their introduction and offer assistance. Let me make sure to respond warmly and ask how I can help them today. I'll keep it friendly and open-ended.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 19, 'total_tokens': 131, 'completion_time': 0.244956983, 'completion_tokens_details': {'reasoning_tokens': 47}, 'prompt_time': 0.000655941, 'prompt_tokens_details': None, 'queue_time': 0.046034125, 'total_time': 0.245612924}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c6-c2c0-7401-bbb8-a096b893af91-0', usage_metadata={'input_tokens': 19, 'output_tokens': 112, 'total_tokens': 131, 'output_token_details': {'reasoning': 47}}), HumanMessage(content='Hi my name is Krishna. I am a Data Engineer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Krishna! Nice to meet you again. As a Data Engineer, you likely work with data pipelines, ETL processes, and infrastructure. How can I assist you today? Whether it's about data engineering challenges, tools, best practices, or anything else related to your work, feel free to ask!\", additional_kwargs={'reasoning_content': \"Okay, the user introduced themselves again as Krishna, a Data Engineer. Let me check the history. The previous message was the same, so maybe they sent it twice by accident. I should acknowledge their introduction again but also prompt them to ask a question or share what they need help with. Since they're a Data Engineer, they might need assistance with tools like Apache Airflow, Spark, or cloud services like AWS/GCP. I should keep the response friendly and open-ended to encourage them to specify their needs. Let me make sure the response is welcoming and offers help in areas relevant to their role.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 187, 'prompt_tokens': 100, 'total_tokens': 287, 'completion_time': 0.366594677, 'completion_tokens_details': {'reasoning_tokens': 121}, 'prompt_time': 0.003835218, 'prompt_tokens_details': None, 'queue_time': 0.046723868, 'total_time': 0.370429895}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c6-dde8-7683-ad90-cf2ebf234f71-0', usage_metadata={'input_tokens': 100, 'output_tokens': 187, 'total_tokens': 287, 'output_token_details': {'reasoning': 121}}), HumanMessage(content='My name is dennis. I am a AI developer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Dennis! Nice to meet you. As an AI developer, you likely work on machine learning models, neural networks, or AI-driven solutions. How can I assist you today? Whether it's about model training, deployment, data preprocessing, AI ethics, tools like TensorFlow/PyTorch, or anything else in the AI/ML space‚Äîfeel free to share what you're working on! üòä\", additional_kwargs={'reasoning_content': \"Okay, the user introduced themselves as Dennis, an AI developer. Let me check the history. The previous user was Krishna, a Data Engineer. Now Dennis is new.\\n\\nFirst, I need to acknowledge Dennis's introduction. Since he's an AI developer, maybe he works with machine learning models, frameworks like TensorFlow or PyTorch, or deals with training and deployment. \\n\\nI should ask how I can assist him. Possible areas could be model optimization, data preprocessing, deployment strategies, or AI ethics. Also, maybe he's interested in tools or best practices. \\n\\nI should keep the response friendly and open-ended to encourage him to specify his needs. Make sure not to assume too much but offer a range of possibilities. Let me phrase it in a way that invites him to share more about his current projects or challenges.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 251, 'prompt_tokens': 182, 'total_tokens': 433, 'completion_time': 0.484396823, 'completion_tokens_details': {'reasoning_tokens': 165}, 'prompt_time': 0.007439708, 'prompt_tokens_details': None, 'queue_time': 0.045811672, 'total_time': 0.491836531}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c7-2af0-71f1-957a-1acd218f77e4-0', usage_metadata={'input_tokens': 182, 'output_tokens': 251, 'total_tokens': 433, 'output_token_details': {'reasoning': 165}}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi Dennis! Your name is **Dennis**, as you mentioned earlier. üòä Let me know how I can assist you with your AI development work!', additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What is my name?\" Let me check the conversation history.\\n\\nLooking back, the user first introduced themselves as Krishna, a Data Engineer. Then they said, \"Hi my name is dennis. I am a AI developer.\" So there\\'s a switch here. The user might be testing if I remember the name change or if I can track the context correctly.\\n\\nWait, but in the previous messages, the user first said Krishna, then Dennis. The last message before the current one was from Dennis. So the current user is Dennis. But the user is asking \"What is my name?\" which could be a test to see if I can recall the correct name based on the conversation flow.\\n\\nI need to make sure I address the correct person. Since the last message was from Dennis, the current user is Dennis. However, the user might be trying to confirm if I can track the context properly. Alternatively, maybe there\\'s a confusion in the conversation history.\\n\\nWait, the user might be using multiple identities in the same conversation. But in the history, after Krishna, the user introduced Dennis. So the latest user is Dennis. The question is, when Dennis asks \"What is my name?\", I should respond with Dennis. But maybe the user is checking if I can handle multiple users in the same thread. However, in the current setup, each conversation is with one user. So perhaps the user is testing if I can remember the correct name after switching from Krishna to Dennis.\\n\\nIn that case, the correct answer is Dennis. But I need to make sure I don\\'t mix up the names. Let me verify again. The user first said Krishna, then Dennis. The last message was from Dennis. So the current user is Dennis. Therefore, the answer should be Dennis. But maybe the user is trying to see if I can track the context correctly. So I should respond with Dennis and acknowledge the previous names if necessary. However, the user might just want the current name. Let me check the instructions again. The user wants the assistant to provide a helpful and accurate response. So the correct answer is Dennis. I should respond with that.\\n'}, response_metadata={'token_usage': {'completion_tokens': 474, 'prompt_tokens': 278, 'total_tokens': 752, 'completion_time': 1.5791369259999999, 'completion_tokens_details': {'reasoning_tokens': 438}, 'prompt_time': 0.01220874, 'prompt_tokens_details': None, 'queue_time': 0.158936788, 'total_time': 1.591345666}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95c7-8393-7e61-a253-0f372957ed43-0', usage_metadata={'input_tokens': 278, 'output_tokens': 474, 'total_tokens': 752, 'output_token_details': {'reasoning': 438}})]\n"
     ]
    }
   ],
   "source": [
    "print(store[\"chat1\"].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16b212e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have access to your personal information, including your name. If you'd like me to address you by name in our conversation, feel free to share it with me!\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the session config and ask for your name again\n",
    "config2 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "\n",
    "response1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config2,\n",
    ")\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd3a7a",
   "metadata": {},
   "source": [
    "### Working with chat prompt template\n",
    "\n",
    "https://reference.langchain.com/python/langchain-core/prompts/chat/MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0498d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"history\"),  # history is a variable\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4234d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Dennis! Nice to meet you. How can I assist you today? Feel free to ask me any questions or let me know if there's something specific you'd like help with. üòä\", additional_kwargs={'reasoning_content': \"Okay, the user introduced themselves as Dennis. I should acknowledge their name and offer assistance. Let me make sure to use their name in the response to personalize the interaction. I'll keep it friendly and open-ended to encourage them to ask questions or share what's on their mind. Let me check for any typos and ensure the tone is welcoming.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 25, 'total_tokens': 139, 'completion_time': 0.221469843, 'completion_tokens_details': {'reasoning_tokens': 70}, 'prompt_time': 0.000832029, 'prompt_tokens_details': None, 'queue_time': 0.04697828, 'total_time': 0.222301872}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c95fe-ace6-7873-9312-116643a53d99-0', usage_metadata={'input_tokens': 25, 'output_tokens': 114, 'total_tokens': 139, 'output_token_details': {'reasoning': 70}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"history\": [HumanMessage(content=\"Hi my name is dennis\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "548c17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "191180fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello again, Dennis! üòä I'm glad to see you here. As an AI developer, I'd love to hear about your projects or discuss any challenges you're working on. Whether it's machine learning, NLP, computer vision, or something else‚Äîfeel free to share! How can I assist you today? üöÄ\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3 = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "\n",
    "response1 = with_message_history.invoke(\n",
    "    {\"history\": [HumanMessage(content=\"Hi my name is dennis\")]},\n",
    "    config=config3,\n",
    ")\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca0a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt for translation\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\"history\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c416331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§π‡•à‡§≤‡•ã ‡§°‡•á‡§®‡§ø‡§∏! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"history\": [HumanMessage(content=\"Hi my name is dennis\")], \"language\": \"hindi\"}\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecb3d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain, get_session_history, input_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b11d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§°‡•á‡§®‡§ø‡§∏! üòä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å ‡§Ü‡§™‡§ï‡•ã? ‡§ï‡•ã‡§à ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§π‡•à ‡§Ø‡§æ ‡§ï‡•Å‡§õ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config4 = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\"history\": [HumanMessage(content=\"Hi my name is dennis\")], \"language\": \"hindi\"},\n",
    "    config=config4,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68fbb5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§°‡•á‡§®‡§ø‡§∏ ‡§π‡•à‡•§ üòä ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§¨‡§§‡§æ‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"history\": [HumanMessage(content=\"What is my name?\")], \"language\": \"hindi\"},\n",
    "    config=config4,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e9654",
   "metadata": {},
   "source": [
    "### Managing Chat Histories\n",
    "\n",
    "https://reference.langchain.com/python/langchain-core/messages/utils/trim_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78d5979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant, you always respond with a joke.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='and who is harrison chasing anyways', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hmmm let me think.\\n\\nWhy, he's probably chasing after the last cup of coffee in the office!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what do you call a speechless parrot', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='A speechless bird', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    BaseMessage,\n",
    "    SystemMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"you're a good assistant, you always respond with a joke.\"),\n",
    "    HumanMessage(\"i wonder why it's called langchain\"),\n",
    "    AIMessage(\n",
    "        'Well, I guess they thought \"WordRope\" and \"SentenceString\" just '\n",
    "        \"didn't have the same ring to it!\"\n",
    "    ),\n",
    "    HumanMessage(\"and who is harrison chasing anyways\"),\n",
    "    AIMessage(\n",
    "        \"Hmmm let me think.\\n\\nWhy, he's probably chasing after the last \"\n",
    "        \"cup of coffee in the office!\"\n",
    "    ),\n",
    "    HumanMessage(\"what do you call a speechless parrot\"),\n",
    "    AIMessage(\"A speechless bird\"),\n",
    "]\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    # Most chat models expect that chat history starts with either:\n",
    "    # (1) a HumanMessage or\n",
    "    # (2) a SystemMessage followed by a HumanMessage\n",
    "    start_on=\"human\",\n",
    "    # Usually, we want to keep the SystemMessage\n",
    "    # if it's present in the original history.\n",
    "    # The SystemMessage has special instructions for the model.\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    ")\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f5d54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant, you always respond with a joke.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what do you call a speechless parrot', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='A speechless bird', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=45,  # reducing the number of tokens\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    # Most chat models expect that chat history starts with either:\n",
    "    # (1) a HumanMessage or\n",
    "    # (2) a SystemMessage followed by a HumanMessage\n",
    "    start_on=\"human\",\n",
    "    # Usually, we want to keep the SystemMessage\n",
    "    # if it's present in the original history.\n",
    "    # The SystemMessage has special instructions for the model.\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    ")\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "153cd4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked, \"What do you call a speechless parrot?\" and now you\\'re asking about your own questions? That‚Äôs a real brain teaser! üòÑ'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoking through chain\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"history\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "# prompt : refers to prompt template above\n",
    "# history : refers to the variable passed in prompt template\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"history\": messages + [HumanMessage(content=\"what question did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e151c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, the classic \"Why did the chicken cross the road?\" question‚Äîbecause it was tired of being chased by the egg! üêîü•ö'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to access a trimmed message : it will give me a random answer and not the answer from messages.\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"history\": messages + [HumanMessage(content=\"What is the chasing question\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a56f4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap in message history\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history, \n",
    "    input_messages_key=\"history\"\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eda56b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You‚Äôre asking for clarification about a question that hasn‚Äôt been provided in our conversation. To assist you effectively, please share the **specific question** you‚Äôd like me to answer. Without a clear question, I can‚Äôt provide a meaningful response. Let me know how I can help! üòä'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"history\": [HumanMessage(content=\"What is the question asked?\")], \"language\": \"English\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
