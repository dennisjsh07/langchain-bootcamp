{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cdaf41",
   "metadata": {},
   "source": [
    "https://docs.langchain.com/oss/python/integrations/chat/groq\n",
    "\n",
    "https://reference.langchain.com/python/integrations/langchain_groq/?_gl=1*1h2j9gb*_gcl_au*OTUxMDk2OTY1LjE3NjUzODg3MTk.*_ga*MzU0MDUzODIwLjE3NjUzODg3MjA.*_ga_47WX3HKKY2*czE3NjkzOTI0ODEkbzUzJGcwJHQxNzY5MzkyNDgxJGo2MCRsMCRoMA..#langchain_groq.ChatGroq\n",
    "\n",
    "#### refer this link to check sending images as text using groq : https://docs.langchain.com/oss/python/integrations/chat/groq#vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef9871",
   "metadata": {},
   "source": [
    "#### Chatbot using groq_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ca32fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79bc6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\krish_naik\\python\\AI_Bootcamp\\4.Langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"qwen/qwen3-32b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37705667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={'reasoning_content': 'Okay, the user wants to translate \"I love programming.\" into French. Let me start by breaking down the sentence. \"I love\" is straightforward. In French, \"I love\" is \"J\\'adore\" or \"J\\'aime\". Wait, which one is more appropriate here? \"Adorer\" is a bit stronger than \"aimer\". The user might be expressing a strong affection, so \"J\\'adore\" could be better. But maybe they just want the direct translation. Let me check.\\n\\nNext, \"programming\". The French word for programming is \"la programmation\". So putting it together: \"J\\'adore la programmation.\" But wait, sometimes in French, the verb \"aimer\" is used with activities. So \"J\\'aime programmer\" is also correct. Hmm, the user might be looking for the most natural translation. Which one is more common? Both are correct, but \"J\\'adore\" is more emphatic. Let me confirm. If the user says \"I love programming\", using \"J\\'adore\" would convey that strong love. Alternatively, \"J\\'aime beaucoup programmer\" could also work. But the direct translation would be \"J\\'adore la programmation.\" Let me make sure there\\'s no mistake here. Yes, \"programmation\" is the correct noun form. So the translation is correct. I should present both options maybe, but the user asked for the translation, so the most accurate one is \"J\\'adore la programmation.\" Alternatively, \"J\\'aime programmer\" is also correct. Wait, the user might prefer the verb form. Let me check which is more commonly used. In French, both are acceptable. If the user is talking about the activity in general, \"J\\'adore la programmation\" is good. If they\\'re talking about the action, \"J\\'aime programmer\" is also correct. Since the original sentence uses the gerund form \"programming\", maybe the noun form is better. So the best translation is \"J\\'adore la programmation.\" I\\'ll go with that.\\n'}, response_metadata={'token_usage': {'completion_tokens': 444, 'prompt_tokens': 33, 'total_tokens': 477, 'completion_time': 0.894006956, 'completion_tokens_details': {'reasoning_tokens': 431}, 'prompt_time': 0.001141397, 'prompt_tokens_details': None, 'queue_time': 0.159436602, 'total_time': 0.895148353}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bf842-88d6-7440-b176-cde399125cc9-0', usage_metadata={'input_tokens': 33, 'output_tokens': 444, 'total_tokens': 477, 'output_token_details': {'reasoning': 431}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88d911fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'adore la programmation.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7580e3",
   "metadata": {},
   "source": [
    "##### Using LCEL ( Lang chain expression language) to chain components to gether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98ddc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime la programmation.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f8694",
   "metadata": {},
   "source": [
    "##### Using Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76574df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template = \"Translate the following into {language}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", generic_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "result = chain.invoke({\"language\": \"Hindi\", \"text\": \"Hello\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
